<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>face-api.js — Expressions + Nonchalant Overlay</title>
    <style>
      :root {
        color-scheme: dark;
      }
      * {
        box-sizing: border-box;
      }
      body {
        margin: 0;
        background: #0b0b0c;
        color: #fff;
        font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      }
      .wrap {
        min-height: 100svh;
        display: grid;
        place-items: center;
        gap: 12px;
        padding: 24px;
      }
      .stage {
        position: relative;
        width: min(760px, 94vw);
      }
      video,
      canvas {
        width: 100%;
        height: auto;
        display: block;
        border-radius: 16px;
      }
      #hud {
        position: absolute;
        left: 12px;
        top: 12px;
        z-index: 5;
        padding: 8px 12px;
        font-size: 14px;
        border-radius: 12px;
        background: rgba(20, 20, 24, 0.6);
        backdrop-filter: blur(6px);
      }
      #caption {
        position: absolute;
        left: 50%;
        transform: translateX(-50%);
        bottom: 14px;
        z-index: 5;
        padding: 6px 12px;
        font-size: 13px;
        border-radius: 999px;
        letter-spacing: 0.2px;
        background: rgba(15, 15, 20, 0.68);
        display: none;
      }
      #startBtn {
        appearance: none;
        border: 0;
        cursor: pointer;
        border-radius: 12px;
        padding: 10px 14px;
        background: #1e1e24;
        color: #fff;
        font-size: 14px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.25);
      }
      #legend {
        font-size: 13px;
        opacity: 0.85;
      }
      a {
        color: #9ddcff;
        text-decoration: none;
      }
    </style>
  </head>
  <body>
    <div class="wrap">
      <div class="stage">
        <div id="hud">loading…</div>
        <video id="video" autoplay muted playsinline></video>
        <canvas id="overlay"></canvas>
        <div id="caption">nonchalant observer</div>
      </div>
      <button id="startBtn" aria-label="Start">▶ Start</button>
      <div id="legend">
        Expressions: neutral, happy, sad, angry, fearful, disgusted, surprised
      </div>
    </div>

    <!-- Runtimes (CDNs) -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <script>
      const video = document.getElementById("video");
      const overlay = document.getElementById("overlay");
      const ctx = overlay.getContext("2d");
      const hud = document.getElementById("hud");
      const caption = document.getElementById("caption");
      const startBtn = document.getElementById("startBtn");

      // --- neutral smoothing + hysteresis ---
      const neutralBuf = [];
      const BUF_SIZE = 8; // frames to average
      const NEUTRAL_ON = 0.55; // looser so you can see it on GH Pages quickly
      const NEUTRAL_OFF = 0.45;
      let captionOn = false;

      function pushNeutral(p) {
        neutralBuf.push(p);
        if (neutralBuf.length > BUF_SIZE) neutralBuf.shift();
        return neutralBuf.reduce((a, b) => a + b, 0) / neutralBuf.length;
      }

      function bestExpression(expressions) {
        let best = { name: "unknown", score: 0 };
        for (const [name, score] of Object.entries(expressions))
          if (score > best.score) best = { name, score };
        return best;
      }

      function drawBox(box) {
        ctx.strokeStyle = "rgba(255,255,255,.85)";
        ctx.lineWidth = 2;
        ctx.setLineDash([]);
        ctx.strokeRect(box.x, box.y, box.width, box.height);
      }

      function drawLabelOverBox(box, text) {
        const pad = 6;
        ctx.font = "14px system-ui, sans-serif";
        const metrics = ctx.measureText(text);
        const tw = metrics.width,
          th = 18;
        const tx = box.x + Math.max(0, (box.width - tw) / 2);
        const ty = Math.max(0, box.y - th - 8);

        // background pill
        ctx.fillStyle = "rgba(0,0,0,0.6)";
        ctx.fillRect(tx - pad, ty - th + 4, tw + pad * 2, th);

        // text
        ctx.fillStyle = "white";
        ctx.fillText(text, tx, ty);
      }

      function drawNeutralOverlay(box) {
        ctx.save();
        ctx.setLineDash([8, 6]);
        ctx.strokeStyle = "rgba(255,255,255,.9)";
        ctx.lineWidth = 2;
        ctx.strokeRect(box.x, box.y, box.width, box.height);

        const r = Math.max(box.width, box.height);
        const grad = ctx.createRadialGradient(
          box.x + box.width / 2,
          box.y + box.height / 2,
          r * 0.1,
          box.x + box.width / 2,
          box.y + box.height / 2,
          r * 0.7
        );
        grad.addColorStop(0, "rgba(255,255,255,0.03)");
        grad.addColorStop(1, "rgba(0,0,0,0.45)");
        ctx.fillStyle = grad;
        ctx.fillRect(box.x, box.y, box.width, box.height);
        ctx.restore();
      }

      async function loadModels() {
        const MODEL_URL = "./models"; // relative for GitHub Pages subpath
        hud.textContent = "loading models…";
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
          faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL),
        ]);
        hud.textContent = "models ready";
      }

      async function setupCamera() {
        hud.textContent = "requesting camera…";
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "user",
            width: { ideal: 1280 },
            height: { ideal: 720 },
          },
          audio: false,
        });
        video.srcObject = stream;
        await new Promise((r) => (video.onloadedmetadata = r));

        // match canvas to real video size (important on GH Pages / mobile)
        overlay.width = video.videoWidth;
        overlay.height = video.videoHeight;
        hud.textContent = "camera ready";
      }

      function ensureCanvasSizeMatchesVideo() {
        if (
          overlay.width !== video.videoWidth ||
          overlay.height !== video.videoHeight
        ) {
          overlay.width = video.videoWidth;
          overlay.height = video.videoHeight;
        }
      }

      async function startApp() {
        try {
          startBtn.disabled = true;
          await loadModels();
          await setupCamera();

          const opts = new faceapi.TinyFaceDetectorOptions({
            inputSize: 320,
            scoreThreshold: 0.5,
          });

          hud.textContent = "detecting…";

          async function tick() {
            // Keep canvas in sync (helpful after device rotation / layout changes)
            ensureCanvasSizeMatchesVideo();

            const result = await faceapi
              .detectSingleFace(video, opts)
              .withFaceExpressions(); // expressions head is required for labels

            ctx.clearRect(0, 0, overlay.width, overlay.height);

            if (result) {
              const { box } = result.detection;
              drawBox(box);

              const expr = result.expressions || {};
              const keys = Object.keys(expr);

              if (!keys.length) {
                hud.textContent =
                  "face found — expressions missing (check ./models path)";
                caption.style.display = "none";
                return requestAnimationFrame(tick);
              }

              const best = bestExpression(expr);
              const pct = (best.score * 100).toFixed(0);
              drawLabelOverBox(box, `${best.name} ${pct}%`);

              // neutral logic
              const avgNeutral = pushNeutral(expr.neutral ?? 0);
              if (!captionOn && avgNeutral >= NEUTRAL_ON) captionOn = true;
              if (captionOn && avgNeutral < NEUTRAL_OFF) captionOn = false;
              caption.style.display = captionOn ? "" : "none";

              hud.textContent = `expression: ${
                best.name
              } (neutral avg: ${Math.round(avgNeutral * 100)}%)`;
            } else {
              caption.style.display = "none";
              hud.textContent = "no face detected";
            }

            requestAnimationFrame(tick);
          }

          tick();
        } catch (err) {
          console.error(err);
          hud.textContent = "error: " + err.message;
          startBtn.disabled = false;
        }
      }

      // Many mobile browsers require a user gesture to start getUserMedia
      startBtn.addEventListener("click", startApp);
      // Also attempt auto-start on desktop
      window.addEventListener("load", () => {
        // If autoplay fails (mobile), the Start button remains available
        startApp().catch(() => {});
      });
    </script>
  </body>
</html>
